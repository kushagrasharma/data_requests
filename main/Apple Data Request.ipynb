{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for all parsing\n",
    "```python\n",
    "@require(iter_json_gzip,'ujson','datetime','re','gzip','csv')\n",
    "def DUMPNAME(file_in,out_base,compress=1):\n",
    "    headers = [] # list of column names\n",
    "    out_filename = out_base.format('DUMPNAME')\n",
    "    \n",
    "    # Things to remmember as having \"seen\"\n",
    "    seen = set()\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            # get some attribute, cast to strting if need be\n",
    "            # what you're \"remmebering\" can also be a tuple (not list, they're not hashable)\n",
    "            SOMEFIELD = json.get('SOMEFIELD','')\n",
    "            if isinstance(category,str):\n",
    "                category = category.strip()\n",
    "                # double check that it's a valid field, non empty and not seen, etc.\n",
    "                if running.get(json['app_id'],'')!=SOMEFIELD and len(SOMEFIELD)>0:\n",
    "                    # SOME CODE HERE\n",
    "                    csv_writer.writerow(obs)\n",
    "    return out_filename\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibility notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is only compatible with a python 3.4 kernel and the notebook must be opened with ipython 3.0+.\n",
    "\n",
    "The following libraries must be installed to run this code:\n",
    "\n",
    "```pip install ujson```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pdb import set_trace as debug\n",
    "from pandas.io.parsers import read_csv\n",
    "from IPython.parallel import Client,require\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "import csv\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--> RAW_FILE_DIR with the directory that contains google_play__main.json.gz\n",
    "#--> OUT_DIR with the directory of where you want the processed files to go\n",
    "#--> DEBUG whether to print out created CSV files or not\n",
    "#--> COMPRESS_LEVEL gzip compression level. warning: severely impacts runtime.\n",
    "#--> LINE_LIMIT how many lines to iterate through in the raw file. For debugging.\n",
    "DUMP_DATE = '2015_02_26_23_12'\n",
    "RAW_FILE_DIR = '/home/cgaray/data'\n",
    "OUT_DIR = '/home/cgaray/data/rui'\n",
    "DEBUG = 0\n",
    "COMPRESS_LEVEL = 9\n",
    "LINE_LIMIT = -1\n",
    "PARALLEL = 1\n",
    "PIGZ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't change these!\n",
    "RAW_FILE = '{}/apple_ios__main.json.gz'.format(RAW_FILE_DIR)\n",
    "OUT_BASE = OUT_DIR+'/{}__apple_ios__main__'+DUMP_DATE+'.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if PIGZ:\n",
    "    @require(gzip)\n",
    "    def iter_json_gzip(filename,LINE_LIMIT=LINE_LIMIT):\n",
    "        return gzip.iter_json_gzip(filename,LINE_LIMIT=LINE_LIMIT)\n",
    "        \n",
    "else:\n",
    "    import datautils\n",
    "    @require('datautils')\n",
    "    def iter_json_gzip(filename,LINE_LIMIT=LINE_LIMIT):\n",
    "        return datautils.iter_json_gzip(filename,LINE_LIMIT=LINE_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a couple observations to inspect daw data.\n",
    "# !zcat! \"$RAW_FILE\"|head -n 1000000 | tail -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Parallel Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 active computing engines\n",
      "[(2, 4), (6, 4), (8, 4), (12, 6), (13, 6), (17, 12)]\n"
     ]
    }
   ],
   "source": [
    "if PARALLEL:\n",
    "    ipython_parallel = Client()\n",
    "    print(\"{} active computing engines\".format(len(ipython_parallel.ids)))\n",
    "\n",
    "    lbv = ipython_parallel.load_balanced_view()\n",
    "\n",
    "    map = lambda f,itertable:lbv.map(f,itertable,\\\n",
    "    block =False,\\\n",
    "    ordered =False)\n",
    "\n",
    "    @require('socket')\n",
    "    def host(dummy):\n",
    "        return socket.gethostname()\n",
    "    \n",
    "    nodes = list(lbv.map(host,ipython_parallel.ids))\n",
    "    nodes = [int(x.split('equity')[1].split(\".\")[0]) for x in nodes]\n",
    "    nodes = nodes\n",
    "\n",
    "    print(sorted(list(Counter(nodes).items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWWEBSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWWEBSITE(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','url']\n",
    "    out_filename = out_base.format('NEWWEBSITE')\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        http = re.compile(r\"(http://)|(https://)\")\n",
    "        www = re.compile(r\"^www\\.\")\n",
    "        ending = re.compile(r\"\\.(a-z)(.*?)^\")\n",
    "        bad = re.compile(r\"\\.[a-z]+(.*?)$\")\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            website = json.get('websiteUrl','')\n",
    "            if isinstance(website,str):\n",
    "                website = http.sub('',website).lower()\n",
    "                website = www.sub('',website)\n",
    "                website = website.split(r\"/\")[0]\n",
    "                bad_str = bad.findall(website)\n",
    "                if bad_str:\n",
    "                    website = website.replace(bad_str[0],'')\n",
    "                if running.get(json['app_id'],'')!=website and len(website)>0:\n",
    "                    running[json['app_id']] = website\n",
    "                    day = datetime.datetime.\\\n",
    "                    fromtimestamp(int(json['timestamp']))\\\n",
    "                            .strftime('%Y-%m-%d').strip()\n",
    "                    obs = (json['app_id'],day,website)\n",
    "                    csv_writer.writerow(obs)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWWEBSITE(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWSUPPORTURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWSUPPORTURL(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','support_url']\n",
    "    out_filename = out_base.format('NEWSUPPORTURL')\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        http = re.compile(r\"(http://)|(https://)\")\n",
    "        www = re.compile(r\"^www\\.\")\n",
    "        ending = re.compile(r\"\\.(a-z)(.*?)^\")\n",
    "        bad = re.compile(r\"\\.[a-z]+(.*?)$\")\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            website = json.get('supportUrl','')\n",
    "            if isinstance(website,str):\n",
    "                website = http.sub('',website).lower()\n",
    "                website = www.sub('',website)\n",
    "                website = website.split(r\"/\")[0]\n",
    "                bad_str = bad.findall(website)\n",
    "                if bad_str:\n",
    "                    website = website.replace(bad_str[0],'')\n",
    "                if running.get(json['app_id'],'')!=website and len(website)>0:\n",
    "                    running[json['app_id']] = website\n",
    "                    day = datetime.datetime.\\\n",
    "                    fromtimestamp(int(json['timestamp']))\\\n",
    "                            .strftime('%Y-%m-%d').strip()\n",
    "                    obs = (json['app_id'],day,website)\n",
    "                    csv_writer.writerow(obs)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWSUPPORTURL(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWSIMILAR5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWSIMILAR5(file_in,out_base,compress=1,number_similar = 5):\n",
    "    headers = ['app_id','date']+ ['related{}'.format(x) \\\n",
    "                                  for x in range(1,number_similar+1)]\n",
    "    out_filename = out_base.format('NEWSIMILAR{}'.format(number_similar))\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',9) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            related = json.get('customersAlsoBoughtApps',[])\n",
    "            if related:\n",
    "                related = sorted(map(str, related[:number_similar]))\n",
    "                joined = \",\".join(related)\n",
    "                if running.get(json['app_id'],'')!=joined:\n",
    "                    running[json['app_id']] = joined\n",
    "                    day = datetime.datetime.\\\n",
    "                    fromtimestamp(int(json['timestamp']))\\\n",
    "                            .strftime('%Y-%m-%d').strip()\n",
    "                    csv_writer.writerow([json['app_id'],day]+ related)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWSIMILAR5(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NEWSIMILAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(NEWSIMILAR5)\n",
    "def NEWSIMILAR10(RAW_FILE,OUT_BASE,COMPRESS_LEVEL):\n",
    "    return NEWSIMILAR5(RAW_FILE,OUT_BASE,COMPRESS_LEVEL,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWSIMILAR10(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWSIMILAR15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@require(NEWSIMILAR5)\n",
    "def NEWSIMILAR15(RAW_FILE,OUT_BASE,COMPRESS_LEVEL):\n",
    "    return NEWSIMILAR5(RAW_FILE,OUT_BASE,COMPRESS_LEVEL,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWSIMILAR15(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAILYRATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def DAILYRATINGS(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','rating5','rating4','rating3','rating2','rating1']\n",
    "    out_filename = out_base.format('DAILYRATINGS')\n",
    "    unique_daily_rating = set()\n",
    "    with gzip.open(out_filename,'wt',9) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            day = datetime.datetime.fromtimestamp(int(json['timestamp']))\\\n",
    "                                .strftime('%Y-%m-%d')\n",
    "            rating = json.get('ratingCountList',None)\n",
    "            if rating:\n",
    "                obs = (json['app_id'],day,tuple(rating),)\n",
    "                if hash(obs) not in unique_daily_rating:\n",
    "                    unique_daily_rating.add(hash(obs))\n",
    "                    csv_writer.writerow([json['app_id'],day]+rating)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(DAILYRATINGS(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAILYRATINGSCURRENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def DAILYRATINGSCURRENT(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','rating5','rating4','rating3','rating2','rating1']\n",
    "    out_filename = out_base.format('DAILYRATINGSCURRENT')\n",
    "    unique_daily_rating = set()\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            day = datetime.datetime.fromtimestamp(int(json['timestamp']))\\\n",
    "                                .strftime('%Y-%m-%d')\n",
    "            rating = json.get('ratingCountList_current',None)\n",
    "            if rating:\n",
    "                obs = (json['app_id'],day,tuple(rating),)\n",
    "                if hash(obs) not in unique_daily_rating:\n",
    "                    unique_daily_rating.add(hash(obs))\n",
    "                    csv_writer.writerow([json['app_id'],day]+rating)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Will be empty because this variable wasn't scraped for the first couple million observations\n",
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(DAILYRATINGSCURRENT(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEKLYRATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def WEEKLYRATINGS(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','year','week','rating5','rating4','rating3','rating2','rating1']\n",
    "    out_filename = out_base.format('WEEKLYRATINGS')\n",
    "    unique_daily_rating = set()\n",
    "    with gzip.open(out_filename,'wt',9) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            year,week = datetime.datetime.fromtimestamp(int(json['timestamp']))\\\n",
    "                                .isocalendar()[:2]\n",
    "            rating = json.get('ratingCountList',None)\n",
    "            if rating:\n",
    "                obs = (json['app_id'],year,week)\n",
    "                if hash(obs) not in unique_daily_rating:\n",
    "                    unique_daily_rating.add(hash(obs))\n",
    "                    csv_writer.writerow([json['app_id'],year,week]+rating)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(WEEKLYRATINGS(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEKLYRATINGSCURRENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def WEEKLYRATINGSCURRENT(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','year','week','rating5','rating4','rating3','rating2','rating1']\n",
    "    out_filename = out_base.format('WEEKLYRATINGSCURRENT')\n",
    "    unique_daily_rating = set()\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            year,week = datetime.datetime.fromtimestamp(int(json['timestamp']))\\\n",
    "                                .isocalendar()[:2]\n",
    "            rating = json.get('ratingCountList_current',None)\n",
    "            if rating:\n",
    "                obs = (json['app_id'],year,week)\n",
    "                if hash(obs) not in unique_daily_rating:\n",
    "                    unique_daily_rating.add(hash(obs))\n",
    "                    csv_writer.writerow([json['app_id'],year,week]+rating)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(WEEKLYRATINGSCURRENT(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONTHLYRATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def MONTHLYRATINGS(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','year','month','rating5','rating4','rating3','rating2','rating1']\n",
    "    out_filename = out_base.format('MONTHLYRATINGS')\n",
    "    unique_daily_rating = set()\n",
    "    with gzip.open(out_filename,'wt',9) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            dateobj = datetime.datetime.fromtimestamp(int(json['timestamp']))\n",
    "            year,month = dateobj.year,dateobj.month\n",
    "            rating = json.get('ratingCountList',None)\n",
    "            if rating:\n",
    "                obs = (json['app_id'],year,month)\n",
    "                if hash(obs) not in unique_daily_rating:\n",
    "                    unique_daily_rating.add(hash(obs))\n",
    "                    csv_writer.writerow([json['app_id'],year,month]+rating)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(MONTHLYRATINGS(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWDEVELOPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWDEVELOPER(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','dev_id']\n",
    "    out_filename = out_base.format('NEWDEVELOPER')\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            developer = str(json.get('artist_id',''))\n",
    "            developer = developer.strip()\n",
    "            if running.get(json['app_id'],'')!=developer \\\n",
    "                        and len(developer)>0 \\\n",
    "                        and developer.isdigit():\n",
    "                running[json['app_id']] = developer\n",
    "                day = datetime.datetime.\\\n",
    "                fromtimestamp(int(json['timestamp']))\\\n",
    "                        .strftime('%Y-%m-%d').strip()\n",
    "                obs = (json['app_id'],day,developer)\n",
    "                csv_writer.writerow(obs)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWDEVELOPER(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWCATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWCATEGORY(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date']+ ['category{}'.format(x) \\\n",
    "                                  for x in range(1,5)]\n",
    "    out_filename = out_base.format('NEWCATEGORY')\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            category = json.get('categories',[])[:4]\n",
    "            joined = \",\".join(category)\n",
    "            if running.get(json['app_id'],'')!=joined:\n",
    "                running[json['app_id']] = joined\n",
    "                day = datetime.datetime.\\\n",
    "                fromtimestamp(int(json['timestamp']))\\\n",
    "                        .strftime('%Y-%m-%d').strip()\n",
    "                csv_writer.writerow([json['app_id'],day]+ category)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWCATEGORY(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWPRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWPRICE(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','price']\n",
    "    out_filename = out_base.format('NEWPRICE')\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            price = str(json.get('price','')).replace(\"$\",\"\")\n",
    "            if running.get(json['app_id'],'')!=price:\n",
    "                running[json['app_id']] = price\n",
    "                day = datetime.datetime.\\\n",
    "                fromtimestamp(int(json['timestamp']))\\\n",
    "                        .strftime('%Y-%m-%d').strip()\n",
    "                obs = (json['app_id'],day,price)\n",
    "                csv_writer.writerow(obs) \n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWPRICE(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALLVERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def ALLVERSIONS(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','version_string',\\\n",
    "#                'release_notes'\\\n",
    "              ]\n",
    "    out_filename = out_base.format('ALLVERSIONS')\n",
    "    unique_ver = set()\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            for each_version in json.get('version',[]):\n",
    "                # need extra code because Apple changed format\n",
    "                if 'release-date' in each_version:\n",
    "                    date = each_version.get('release-date','')\n",
    "                    date = datetime.datetime.strptime(date,'%b %d, %Y')\n",
    "                    date = date.strftime('%Y-%m-%d')\n",
    "                    version_string = each_version.get('version-string','')\n",
    "                    release_notes = each_version.get('release-notes','')\n",
    "                elif 'releaseDate' in each_version:\n",
    "                    date = each_version.get('releaseDate','')\n",
    "                    date = datetime.datetime.strptime(date,'%Y-%m-%dT%H:%M:%SZ')\n",
    "                    date = date.strftime('%Y-%m-%d')\n",
    "                    version_string = each_version.get('versionString','')\n",
    "                    release_notes = each_version.get('releaseNotes','')\n",
    "                obs_u = (json['app_id'],date,version_string)\n",
    "                if hash(obs_u) not in unique_ver:\n",
    "                    unique_ver.add(hash(obs_u))\n",
    "                    obs = (json['app_id'],date,\n",
    "                           version_string,\n",
    "#                            release_notes,\n",
    "                          )\n",
    "                    csv_writer.writerow(obs)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(ALLVERSIONS(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWREQ(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','requires','optimized']\n",
    "    out_filename = out_base.format('NEWREQ')\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file, dialect='excel')\n",
    "        csv_writer.writerow(headers)\n",
    "        running = {}\n",
    "        and_re = re.compile(r\"and \")\n",
    "        com_with_re = re.compile(r\"Compatible with \")\n",
    "        optimize_re = re.compile(r\"This app is optimized for \")\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            requires = json.get('requirements',None)\n",
    "            if requires == None:\n",
    "                continue\n",
    "            re_split = requires.split(\".\")\n",
    "            requires = com_with_re.sub('',re_split[0]).strip()\n",
    "            requires = and_re.sub('',requires)\n",
    "            optimized = None\n",
    "            if len(re_split)>1:\n",
    "                optimized = re_split[1].strip()\n",
    "                optimized = optimize_re.sub(\"\",optimized)\n",
    "            if running.get(json['app_id'],'')!=json.get('requirements',''):\n",
    "                running[json['app_id']] = json.get('requirements','')\n",
    "                day = datetime.datetime.fromtimestamp(int(json['timestamp']))\\\n",
    "                        .strftime('%Y-%m-%d')\n",
    "                obs = (json['app_id'],day,requires,optimized)\n",
    "                csv_writer.writerow(obs)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWREQ(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWARTIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWARTIST(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','artist_name']\n",
    "    out_filename = out_base.format('NEWARTIST')\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            developer = json.get('artistName','')\n",
    "            if running.get(json['app_id'],'')!=developer:\n",
    "                running[json['app_id']] = developer\n",
    "                day = datetime.datetime.\\\n",
    "                fromtimestamp(int(json['timestamp']))\\\n",
    "                        .strftime('%Y-%m-%d').strip()\n",
    "                obs = (json['app_id'],day,developer)\n",
    "                csv_writer.writerow(obs)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>date</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [app_id, date, artist_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWARTIST(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWREVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWREVIEW(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','total_reviews']\n",
    "    out_filename = out_base.format('NEWREVIEW')\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            total_reviews = str(json.get('totalNumberOfReviews',''))\n",
    "            if running.get(json['app_id'],'')!= total_reviews:\n",
    "                running[json['app_id']] = total_reviews\n",
    "                day = datetime.datetime.\\\n",
    "                fromtimestamp(int(json['timestamp']))\\\n",
    "                        .strftime('%Y-%m-%d').strip()\n",
    "                obs = (json['app_id'],day,total_reviews)\n",
    "                csv_writer.writerow(obs)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>date</th>\n",
       "      <th>total_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281656475</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>281704574</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>12689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281736535</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281790044</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>281796108</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>281816692</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>281826146</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>281861187</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281889893</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>281893011</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>281913144</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>281935788</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>281940292</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>281941097</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>281944480</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>281952554</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>281962101</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>281969989</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>282614216</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>282737873</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>282738621</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>282758413</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>282764294</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>282769257</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>282778557</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>282796383</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>282841854</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>282860910</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>282914454</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>282935706</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>3209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>283561712</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>283595343</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>283608109</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>283619399</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>283621361</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>283646709</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>283698947</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>283725734</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>283728779</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>283730004</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>283730668</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>283835623</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>283853762</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>283909107</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>283914070</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>4998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>283922359</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>283927946</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>283998370</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>284000015</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>284000231</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>284010199</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>284011966</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>284016143</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>284031574</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>284034778</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>284035177</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>24188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>284038820</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>284043092</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>284070727</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>284072607</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       app_id        date  total_reviews\n",
       "0   281656475  2010-09-06            446\n",
       "1   281704574  2010-09-06          12689\n",
       "2   281736535  2010-09-06           2862\n",
       "3   281790044  2010-09-06           1464\n",
       "4   281796108  2010-09-06           1548\n",
       "5   281816692  2010-09-06            934\n",
       "6   281826146  2010-09-06            222\n",
       "7   281861187  2010-09-06             15\n",
       "8   281889893  2010-09-06            198\n",
       "9   281893011  2010-09-06            698\n",
       "10  281913144  2010-09-06           2235\n",
       "11  281935788  2010-09-06            987\n",
       "12  281940292  2010-09-06           1552\n",
       "13  281941097  2010-09-06           1255\n",
       "14  281944480  2010-09-06             71\n",
       "15  281952554  2010-09-06           2106\n",
       "16  281962101  2010-09-06              8\n",
       "17  281969989  2010-09-06            949\n",
       "18  282614216  2010-09-06           2311\n",
       "19  282737873  2010-09-06             23\n",
       "20  282738621  2010-09-06             12\n",
       "21  282758413  2010-09-06             95\n",
       "22  282764294  2010-09-06            138\n",
       "23  282769257  2010-09-06            235\n",
       "24  282778557  2010-09-06           1440\n",
       "25  282796383  2010-09-06             24\n",
       "26  282841854  2010-09-06             56\n",
       "27  282860910  2010-09-06             41\n",
       "28  282914454  2010-09-06             28\n",
       "29  282935706  2010-09-06           3209\n",
       "..        ...         ...            ...\n",
       "64  283561712  2010-09-06             25\n",
       "65  283595343  2010-09-06            410\n",
       "66  283608109  2010-09-06              4\n",
       "67  283619399  2010-09-06            281\n",
       "68  283621361  2010-09-06              6\n",
       "69  283646709  2010-09-06            919\n",
       "70  283698947  2010-09-06            122\n",
       "71  283725734  2010-09-06              5\n",
       "72  283728779  2010-09-06             73\n",
       "73  283730004  2010-09-06            110\n",
       "74  283730668  2010-09-06             28\n",
       "75  283835623  2010-09-06             51\n",
       "76  283853762  2010-09-06            282\n",
       "77  283909107  2010-09-06            848\n",
       "78  283914070  2010-09-06           4998\n",
       "79  283922359  2010-09-06            200\n",
       "80  283927946  2010-09-06              8\n",
       "81  283998370  2010-09-06             20\n",
       "82  284000015  2010-09-06             16\n",
       "83  284000231  2010-09-06              3\n",
       "84  284010199  2010-09-06             76\n",
       "85  284011966  2010-09-06              4\n",
       "86  284016143  2010-09-06             52\n",
       "87  284031574  2010-09-06             28\n",
       "88  284034778  2010-09-06              7\n",
       "89  284035177  2010-09-06          24188\n",
       "90  284038820  2010-09-06             48\n",
       "91  284043092  2010-09-06              4\n",
       "92  284070727  2010-09-06             55\n",
       "93  284072607  2010-09-06              6\n",
       "\n",
       "[94 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWREVIEW(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWSELLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@require(iter_json_gzip,gzip,datetime,re,csv)\n",
    "def NEWSELLER(file_in,out_base,compress=1):\n",
    "    headers = ['app_id','date','seller']\n",
    "    out_filename = out_base.format('NEWSELLER')\n",
    "    running = {}\n",
    "    with gzip.open(out_filename,'wt',compress) as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        csv_writer.writerow(headers)\n",
    "        for json in iter_json_gzip(file_in):\n",
    "            developer = '{}'.format(json['seller'])\n",
    "            if running.get(json['app_id'],None)!=developer:\n",
    "                running[json['app_id']] = developer\n",
    "                day = datetime.datetime.\\\n",
    "                fromtimestamp(int(json['timestamp']))\\\n",
    "                        .strftime('%Y-%m-%d').strip()\n",
    "                obs = (json['app_id'],day,developer)\n",
    "                csv_writer.writerow(obs)\n",
    "    return out_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>date</th>\n",
       "      <th>seller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281656475</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Namco Networks America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>281704574</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>AOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281736535</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Pangea Software Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281790044</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>WHERE Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>281796108</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Evernote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>281816692</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Handmark Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>281826146</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>salesforce.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>281861187</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Hudson Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281889893</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Hudson Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>281893011</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Hudson Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>281913144</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>AOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>281935788</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Epocrates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>281940292</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>AWS Convergence Technologies Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>281941097</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Bloomberg LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>281944480</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Six Apart Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>281952554</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Loopt Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>281962101</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Modality Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>281969989</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Major League Baseball Advanced Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>282614216</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>eBay Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>282737873</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Polka Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>282738621</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Samuel Quinn Slack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>282750724</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Vlad Lungu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>282758413</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Werner Freytag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>282764294</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Gameloft S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>282769257</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Appigo Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>282778557</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Appigo Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>282796383</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Clint Bagwell Consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>282841854</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>James Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>282860910</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Four Corners Development Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>282914454</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Paul Schmitt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>283608109</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Stevens Creek Software LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>283619399</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>MobileAge Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>283621361</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>On-Core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>283646709</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>PayPal an eBay Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>283698947</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>MobileAge Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>283725734</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Ken Torimaru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>283728779</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Rawthought Technologies LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>283730004</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Kevin Kozan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>283730668</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>AcroDesign Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>283835623</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Stevens Creek Software LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>283853762</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Mark Terry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>283854851</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Alex Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>283909107</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>J Allen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>283914070</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Hottrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>283916003</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Random5 LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>283922359</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Jeremie Engel Engel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>283927946</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>CHS Systems LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>283998370</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>KUMAGAI Kentaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>284000015</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>LionClock Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>284000231</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>LionClock Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>284010199</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Shihua Zhang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>284011966</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Clint Bagwell Consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>284016143</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>George Grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>284031574</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Magnetism Studios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>284034778</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>ZappTek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>284035177</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Pandora Media Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>284038820</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Philip Dhingra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>284043092</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Francis Bonnin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>284070727</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Jirbo Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>284072607</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>Jirbo Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       app_id        date                                seller\n",
       "0   281656475  2010-09-06                Namco Networks America\n",
       "1   281704574  2010-09-06                                   AOL\n",
       "2   281736535  2010-09-06                  Pangea Software Inc.\n",
       "3   281790044  2010-09-06                            WHERE Inc.\n",
       "4   281796108  2010-09-06                              Evernote\n",
       "5   281816692  2010-09-06                         Handmark Inc.\n",
       "6   281826146  2010-09-06                        salesforce.com\n",
       "7   281861187  2010-09-06                  Hudson Entertainment\n",
       "8   281889893  2010-09-06                  Hudson Entertainment\n",
       "9   281893011  2010-09-06                  Hudson Entertainment\n",
       "10  281913144  2010-09-06                                   AOL\n",
       "11  281935788  2010-09-06                             Epocrates\n",
       "12  281940292  2010-09-06     AWS Convergence Technologies Inc.\n",
       "13  281941097  2010-09-06                          Bloomberg LP\n",
       "14  281944480  2010-09-06                        Six Apart Ltd.\n",
       "15  281952554  2010-09-06                             Loopt Inc\n",
       "16  281962101  2010-09-06                         Modality Inc.\n",
       "17  281969989  2010-09-06  Major League Baseball Advanced Media\n",
       "18  282614216  2010-09-06                             eBay Inc.\n",
       "19  282737873  2010-09-06                        Polka Networks\n",
       "20  282738621  2010-09-06                    Samuel Quinn Slack\n",
       "21  282750724  2010-09-06                            Vlad Lungu\n",
       "22  282758413  2010-09-06                        Werner Freytag\n",
       "23  282764294  2010-09-06                         Gameloft S.A.\n",
       "24  282769257  2010-09-06                           Appigo Inc.\n",
       "25  282778557  2010-09-06                           Appigo Inc.\n",
       "26  282796383  2010-09-06              Clint Bagwell Consulting\n",
       "27  282841854  2010-09-06                             James Lee\n",
       "28  282860910  2010-09-06        Four Corners Development Group\n",
       "29  282914454  2010-09-06                          Paul Schmitt\n",
       "..        ...         ...                                   ...\n",
       "70  283608109  2010-09-06            Stevens Creek Software LLC\n",
       "71  283619399  2010-09-06                         MobileAge Inc\n",
       "72  283621361  2010-09-06                               On-Core\n",
       "73  283646709  2010-09-06                PayPal an eBay Company\n",
       "74  283698947  2010-09-06                         MobileAge Inc\n",
       "75  283725734  2010-09-06                          Ken Torimaru\n",
       "76  283728779  2010-09-06           Rawthought Technologies LLC\n",
       "77  283730004  2010-09-06                           Kevin Kozan\n",
       "78  283730668  2010-09-06               AcroDesign Technologies\n",
       "79  283835623  2010-09-06            Stevens Creek Software LLC\n",
       "80  283853762  2010-09-06                            Mark Terry\n",
       "81  283854851  2010-09-06                            Alex Price\n",
       "82  283909107  2010-09-06                               J Allen\n",
       "83  283914070  2010-09-06                               Hottrix\n",
       "84  283916003  2010-09-06                           Random5 LLC\n",
       "85  283922359  2010-09-06                   Jeremie Engel Engel\n",
       "86  283927946  2010-09-06                       CHS Systems LLC\n",
       "87  283998370  2010-09-06                       KUMAGAI Kentaro\n",
       "88  284000015  2010-09-06                    LionClock Software\n",
       "89  284000231  2010-09-06                    LionClock Software\n",
       "90  284010199  2010-09-06                          Shihua Zhang\n",
       "91  284011966  2010-09-06              Clint Bagwell Consulting\n",
       "92  284016143  2010-09-06                           George Grey\n",
       "93  284031574  2010-09-06                     Magnetism Studios\n",
       "94  284034778  2010-09-06                               ZappTek\n",
       "95  284035177  2010-09-06                    Pandora Media Inc.\n",
       "96  284038820  2010-09-06                        Philip Dhingra\n",
       "97  284043092  2010-09-06                        Francis Bonnin\n",
       "98  284070727  2010-09-06                            Jirbo Inc.\n",
       "99  284072607  2010-09-06                            Jirbo Inc.\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_debug = None\n",
    "if DEBUG:\n",
    "    df_debug = read_csv(NEWSELLER(RAW_FILE,OUT_BASE,COMPRESS_LEVEL),compression='gzip',header=0)\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run them all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NEWWEBSITE\n",
    "# NEWSUPPORTURL\n",
    "# NEWSIMILAR5\n",
    "# NEWSIMILAR10\n",
    "# NEWSIMILAR15\n",
    "# DAILYRATINGS\n",
    "# DAILYRATINGSCURRENT\n",
    "# WEEKLYRATINGS\n",
    "# WEEKLYRATINGSCURRENT\n",
    "# MONTHLYRATINGS\n",
    "# NEWDEVELOPER\n",
    "# NEWCATEGORY\n",
    "# NEWPRICE\n",
    "# ALLVERSIONS\n",
    "# NEWREQ\n",
    "programs = \"\"\"\n",
    "NEWARTIST\n",
    "NEWREVIEW\n",
    "NEWSELLER\n",
    "\"\"\".split()\n",
    "\n",
    "def run_function(f,RAW_FILE=RAW_FILE,OUT_BASE=OUT_BASE,COMPRESS_LEVEL=COMPRESS_LEVEL):\n",
    "    return f(RAW_FILE ,OUT_BASE,COMPRESS_LEVEL)\n",
    "\n",
    "for file in map(run_function,[globals()[x] for x in programs]):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
